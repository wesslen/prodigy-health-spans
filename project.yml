title: "NER/spancat Prodigy workflow with med7 model"
description: "This project uses [Prodigy](https://prodi.gy) to annotate and fine-tune [`med7`](https://github.com/kormilitzin/med7) spaCy pipeline"
# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  config: "config.cfg"
  name: "ner_med7_improved"
  version: "0.0.0"
  generate-prompt: "Generate doctor's notes precribing drugs, dosages, form, duration, route, strength, and frequency."
  generate-file: "health-generated.jsonl"
  generate-n: 65
  train: "train"
  dev: "dev"

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "training", "configs", "scripts", "corpus", "packages"]

# Assets that should be downloaded or available in the directory. We're shipping
# them with the project, so they won't have to be downloaded. But the
# 'project assets' command still lets you verify that the checksums match.
# assets:
#   - dest: "assets/health-generated.jsonl"
#     # checksum: "4461081e67d8160cab4624e61448f371"
#     description: "JSONL synthetic data generated by LLMs"

# Workflows are sequences of commands (see below) executed in order. You can
# run them via "spacy project run [workflow]". If a commands's inputs/outputs
# haven't changed, it won't be re-run.
# workflows:
#   all:
#     - download
#     - train
#     - evaluate

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:  
  - name: "generate-data"
    script:
      - "dotenv run -- python3 -m prodigy terms.openai.fetch \"${vars.generate-prompt}\" ./assets/${vars.generate-file} --n ${vars.generate-n}"
    help: "Create synthetic data from LLM"

  - name: "prodigy-ner-correct"
    help: "Prodigy ner correct on synthetic doctor's notes"
    script:
      - "python3.9 -m prodigy ner.correct ner-correct-med7 en_core_med7_lg ./assets/${vars.generate-file} --label labels.txt"

  - name: "ner-data-to-spacy"
    help: "Convert Prodigy annotations to spaCy binary files and config file"
    script:
      - "python3.9 -m prodigy data-to-spacy --ner ner-correct-med7 --base-model en_core_med7_lg ./corpus"

  - name: "train"
    help: "Train a named entity recognition model"
    script:
      - "python3.9 -m spacy train corpus/${vars.config} --output training/ --paths.train corpus/${vars.train}.spacy --paths.dev corpus/${vars.dev}.spacy --paths.vectors en_core_med7_lg"
    deps:
      - "corpus/${vars.train}.spacy"
      - "corpus/${vars.dev}.spacy"
    outputs:
      - "training/model-best"

  - name: "evaluate"
    help: "Evaluate the model and export metrics"
    script:
      - "python3 -m spacy evaluate training/model-best corpus/${vars.dev}.spacy --output training/metrics.json"
    deps:
      - "corpus/${vars.dev}.spacy"
      - "training/model-best"
    outputs:
      - "training/metrics.json"

  - name: package
    help: "Package the trained model so it can be installed"
    script:
      - "python3 -m spacy package training/model-best packages --name ${vars.name} --version ${vars.version} --force"
    deps:
      - "training/model-best"
    outputs_no_cache:
      - "packages/en_${vars.name}-${vars.version}/dist/en_${vars.name}-${vars.version}.tar.gz"

  - name: visualize-model
    help: Visualize the model's output interactively using Streamlit
    script:
      - "streamlit run scripts/visualize_model.py"
    deps:
      - "scripts/visualize_model.py"
      - "training/model-last"
      - "training/model-best"